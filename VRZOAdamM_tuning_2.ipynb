{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import time\n",
        "from typing import Callable, Optional, Tuple, Dict, Any"
      ],
      "metadata": {
        "id": "wtn-LAIyX0Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)"
      ],
      "metadata": {
        "id": "rW3ZowFWnFeK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de0ade7-89f6-4dc8-c5a4-0f6d6a992b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def zo_adamm(\n",
        "    # required\n",
        "    model_or_predict: Any,            # either a torch.nn.Module OR a callable predict_fn(batch_tensor)->logits\n",
        "    x0,                               # numpy array or torch tensor with shape (C,H,W) or (1,C,H,W)\n",
        "    true_label: int,\n",
        "\n",
        "    # ZO / VR hyperparams\n",
        "    mu: float = 1e-2,\n",
        "    q: int = 64,\n",
        "    Q_ref: int = 256,\n",
        "    inner_m: int = 20,\n",
        "    epochs: int = 5,\n",
        "    dist_weight: float = 0.01,\n",
        "\n",
        "    # Adam-like\n",
        "    alpha: float = 0.05,\n",
        "    beta1: float = 0.9,\n",
        "    beta2: float = 0.99,\n",
        "    eps: float = 1e-8,\n",
        "    v_init: float = 1e-6,\n",
        "\n",
        "    # projection / constraints\n",
        "    constrained: bool = True,\n",
        "    lb: float = -0.5,\n",
        "    ub: float = 0.5,\n",
        "\n",
        "    # batching / device\n",
        "    device: Optional[torch.device] = None,\n",
        "    forward_batch_size: int = 256,   # split model batches when evaluating many probes\n",
        "    rng_seed: int = 1234,\n",
        "\n",
        "    # stopping / budgets\n",
        "    early_stop: bool = True,\n",
        "    stop_threshold: float = 0.0,\n",
        "    max_queries: int = 50000,\n",
        "    max_distortion: Optional[float] = None,\n",
        "    patience: int = 40,\n",
        "    tol: float = 1e-3,\n",
        "    smooth_window: int = 20,\n",
        "    flat_threshold: float = 1e-3,\n",
        "\n",
        "    # misc\n",
        "    predict_fn: Optional[Callable[[torch.Tensor], torch.Tensor]] = None,\n",
        "    verbose: bool = True,\n",
        ") -> Tuple[np.ndarray, Dict[str,Any]]:\n",
        "    \"\"\"\n",
        "    ZO–AdaMM (variance-reduction removed) generalized for arbitrary PyTorch model.\n",
        "\n",
        "    Returns:\n",
        "      delta (numpy array shape d,) : perturbation vector to add to x0 (flattened)\n",
        "      diagnostics: dict with keys: queries, history: {loss, queries, dist}, stop_reason, time_elapsed\n",
        "\n",
        "    Query counting convention: 1 forward on B images -> +B queries.\n",
        "    \"\"\"\n",
        "\n",
        "    # ---------- prepare device and predict function ----------\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # if user passed a model, make default predict_fn\n",
        "    if predict_fn is None:\n",
        "        if callable(model_or_predict):\n",
        "            # assume model_or_predict is a torch.nn.Module\n",
        "            model = model_or_predict\n",
        "            model.eval()\n",
        "            model.to(device)\n",
        "            def _predict_fn(batch: torch.Tensor) -> torch.Tensor:\n",
        "                # expects batch on same device\n",
        "                with torch.no_grad():\n",
        "                    return model(batch)\n",
        "            predict = _predict_fn\n",
        "        else:\n",
        "            raise ValueError(\"Either provide a model (nn.Module) as model_or_predict or pass predict_fn explicitly.\")\n",
        "    else:\n",
        "        predict = predict_fn\n",
        "\n",
        "    # ---------- prepare x0 and shapes ----------\n",
        "    if isinstance(x0, torch.Tensor):\n",
        "        x0_t = x0.detach().cpu().float()\n",
        "    else:\n",
        "        x0_t = torch.from_numpy(np.array(x0)).float()\n",
        "\n",
        "    # support x0 shaped (C,H,W) or (1,C,H,W)\n",
        "    if x0_t.ndim == 3:\n",
        "        C,H,W = x0_t.shape\n",
        "    elif x0_t.ndim == 4 and x0_t.shape[0] == 1:\n",
        "        _, C,H,W = x0_t.shape\n",
        "        x0_t = x0_t.squeeze(0)\n",
        "    else:\n",
        "        raise ValueError(\"x0 must have shape (C,H,W) or (1,C,H,W)\")\n",
        "\n",
        "    d = int(C*H*W)\n",
        "    x_shape = (C,H,W)\n",
        "\n",
        "    # move base x0 to device once\n",
        "    x0_dev = x0_t.to(device)\n",
        "\n",
        "    torch.manual_seed(rng_seed)\n",
        "    rng = np.random.RandomState(rng_seed)\n",
        "\n",
        "    # ---------- helpers ----------\n",
        "    def sample_dirs(q_local:int) -> torch.Tensor:\n",
        "        U = torch.randn((q_local, d), device=device)\n",
        "        norms = U.norm(dim=1, keepdim=True)\n",
        "        norms = torch.where(norms == 0, torch.ones_like(norms), norms)\n",
        "        return U / norms  # (q, d)\n",
        "\n",
        "    def batched_predict(batch_imgs: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Run predict on batch_imgs (N,C,H,W) in sub-batches sized forward_batch_size.\n",
        "        Returns logits tensor (N, n_classes)\n",
        "        Also increments queries by N (handled by callers).\n",
        "        \"\"\"\n",
        "        n = batch_imgs.shape[0]\n",
        "        outs = []\n",
        "        for i in range(0, n, forward_batch_size):\n",
        "            chunk = batch_imgs[i:i+forward_batch_size].to(device)\n",
        "            with torch.no_grad():\n",
        "                out = predict(chunk)\n",
        "            outs.append(out.detach().cpu())\n",
        "        return torch.cat(outs, dim=0).to(device)\n",
        "\n",
        "    def imgs_from_deltas(deltas: torch.Tensor) -> torch.Tensor:\n",
        "        # deltas: (q, d) or (B, d) on device -> returns (q, C, H, W)\n",
        "        return (x0_dev.unsqueeze(0) + deltas.view(-1, C, H, W))\n",
        "\n",
        "    # ZO symmetric estimator using batched forwards:\n",
        "    def symmetric_zo_grad(x: torch.Tensor, mu_t: float, directions: torch.Tensor) -> Tuple[torch.Tensor,int]:\n",
        "        \"\"\"\n",
        "        x: tensor (d,) on device\n",
        "        directions: (q, d) on device\n",
        "        returns: grad_est (d,) on device, queries_added (int)\n",
        "        \"\"\"\n",
        "        q_local = int(directions.shape[0])\n",
        "\n",
        "        delta_plus  = x.unsqueeze(0) + mu_t * directions   # (q,d)\n",
        "        delta_minus = x.unsqueeze(0) - mu_t * directions   # (q,d)\n",
        "\n",
        "        imgs_plus  = imgs_from_deltas(delta_plus).cpu()\n",
        "        imgs_minus = imgs_from_deltas(delta_minus).cpu()\n",
        "\n",
        "        batch = torch.cat([imgs_plus, imgs_minus], dim=0)  # (2q, C, H, W)\n",
        "        logits = batched_predict(batch)  # (2q, nclass)\n",
        "        q_inc = batch.shape[0]\n",
        "\n",
        "        probs = F.softmax(logits, dim=1)  # (2q, C)\n",
        "\n",
        "        # compute margin per sample: log p_true - log max_other\n",
        "        probs_clone = probs.clone()\n",
        "        probs_clone[:, true_label] = float('-inf')\n",
        "        p_true = probs[:, true_label]            # (2q,)\n",
        "        p_other = probs_clone.max(dim=1).values  # (2q,)\n",
        "\n",
        "        margin = torch.log(p_true + 1e-12) - torch.log(p_other + 1e-12)  # (2q,)\n",
        "\n",
        "        # distortion term per delta\n",
        "        dist_plus  = (delta_plus.norm(dim=1)**2).detach()  # (q,)\n",
        "        dist_minus = (delta_minus.norm(dim=1)**2).detach() # (q,)\n",
        "\n",
        "        f_plus  = (margin[:q_local] + dist_weight * dist_plus).detach()\n",
        "        f_minus = (margin[q_local:] + dist_weight * dist_minus).detach()\n",
        "\n",
        "        dir_deriv = (f_plus - f_minus) / (2.0 * mu_t)  # (q,)\n",
        "        grad_est = (d / float(q_local)) * (directions.t() @ dir_deriv)  # (d,)\n",
        "        grad_est = grad_est.to(device)\n",
        "\n",
        "        return grad_est, q_inc\n",
        "\n",
        "    def mahalanobis_projection(x: torch.Tensor, sqrt_vhat: torch.Tensor) -> torch.Tensor:\n",
        "        # x, sqrt_vhat, x0_dev: all on device\n",
        "        z = sqrt_vhat * x\n",
        "        Lb = sqrt_vhat * (lb - x0_dev.view(-1))\n",
        "        Ub = sqrt_vhat * (ub - x0_dev.view(-1))\n",
        "        z_clipped = torch.max(torch.min(z, Ub), Lb)\n",
        "        return z_clipped / sqrt_vhat\n",
        "\n",
        "    # ---------- initialization ----------\n",
        "    # keep x_snap variable for minimal edits (not used for VR anymore)\n",
        "    x_snap = torch.zeros(d, device=device)\n",
        "    x_curr = torch.zeros(d, device=device)\n",
        "    m = torch.zeros(d, device=device)\n",
        "    v = v_init * torch.ones(d, device=device)\n",
        "    vhat = v.clone()\n",
        "\n",
        "    query_count = 0\n",
        "    loss_trace = []\n",
        "    queries_trace = []\n",
        "    dist_trace = []\n",
        "    best_val = float(\"inf\")\n",
        "    no_improve = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    mu_t = float(mu)\n",
        "\n",
        "    # ---------- stopping helper ----------\n",
        "    def check_stopping(val_f: float, delta: torch.Tensor) -> Tuple[bool,str]:\n",
        "        nonlocal best_val, no_improve, query_count\n",
        "        if val_f < stop_threshold:\n",
        "            return True, \"margin reached\"\n",
        "        if (max_distortion is not None) and (float(delta.norm()) > max_distortion):\n",
        "            return True, \"distortion limit exceeded\"\n",
        "        if val_f < best_val - tol:\n",
        "            best_val = val_f\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "        if no_improve > patience:\n",
        "            return True, \"patience exhausted\"\n",
        "        # moving average flattening\n",
        "        loss_trace.append(val_f)\n",
        "        if len(loss_trace) > 2 * smooth_window:\n",
        "            recent = np.mean(loss_trace[-smooth_window:])\n",
        "            previous = np.mean(loss_trace[-2*smooth_window:-smooth_window])\n",
        "            if previous - recent < flat_threshold:\n",
        "                return True, \"moving-average plateau\"\n",
        "        if query_count >= max_queries:\n",
        "            return True, \"query budget exhausted\"\n",
        "        return False, None\n",
        "\n",
        "    # ---------- main loop ----------\n",
        "    stop_reason = None\n",
        "    hist = {\"loss\": [], \"queries\": [], \"dist\": [], \"time\": []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # --- VR reference removed: no reference gradient is computed here anymore ---\n",
        "\n",
        "        # reset moments (optionally you can keep them)\n",
        "        m.zero_()\n",
        "        v = v_init * torch.ones_like(v)\n",
        "        vhat = v.clone()\n",
        "\n",
        "        for t in range(inner_m):\n",
        "            directions = sample_dirs(q)\n",
        "            g_curr, q_inc = symmetric_zo_grad(x_curr, mu_t, directions); query_count += q_inc\n",
        "\n",
        "            # plain ZO gradient (no variance reduction)\n",
        "            g_vr = g_curr\n",
        "\n",
        "            # Adam/AMSGrad\n",
        "            m = beta1 * m + (1.0 - beta1) * g_vr\n",
        "            v = beta2 * v + (1.0 - beta2) * (g_vr * g_vr)\n",
        "            vhat = torch.max(vhat, v)\n",
        "\n",
        "            step = alpha * m / (torch.sqrt(vhat) + eps)\n",
        "            x_new = x_curr - step\n",
        "\n",
        "            if constrained:\n",
        "                sqrt_vhat = torch.sqrt(vhat)\n",
        "                x_new = mahalanobis_projection(x_new, sqrt_vhat)\n",
        "\n",
        "            x_curr = x_new\n",
        "\n",
        "            # evaluate objective once (single forward)\n",
        "            img = (x0_dev + x_curr.view(C,H,W)).unsqueeze(0)  # (1, C, H, W)\n",
        "            logits = batched_predict(img)   # returns (1, nclass) on device\n",
        "            query_count += 1\n",
        "            probs = F.softmax(logits, dim=1)[0]\n",
        "            probs_clone = probs.clone()\n",
        "            probs_clone[true_label] = float('-inf')\n",
        "            p_true = probs[true_label].item()\n",
        "            p_other = probs_clone.max().item()\n",
        "            margin = np.log(p_true + 1e-12) - np.log(p_other + 1e-12)\n",
        "            distortion = float(x_curr.norm()**2)\n",
        "            val = margin + dist_weight * distortion\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "            hist[\"loss\"].append(val)\n",
        "            hist[\"queries\"].append(query_count)\n",
        "            hist[\"dist\"].append(np.sqrt(distortion))\n",
        "            hist[\"time\"].append(elapsed)\n",
        "\n",
        "            if verbose and (t % 10 == 0):\n",
        "                print(f\"[epoch {epoch} step {t}] f={val:.6f} queries={query_count} time={elapsed:.1f}s dist={np.sqrt(distortion):.3f}\")\n",
        "\n",
        "            if early_stop:\n",
        "                stop, reason = check_stopping(val, x_curr)\n",
        "                if stop:\n",
        "                    stop_reason = reason\n",
        "                    if verbose:\n",
        "                        print(\"Early stop:\", reason, \"final f:\", val, \"queries:\", query_count)\n",
        "                    delta_final = x_curr.detach().cpu().numpy()\n",
        "                    diagnostics = {\n",
        "                        \"queries\": int(query_count),\n",
        "                        \"stop_reason\": stop_reason,\n",
        "                        \"history\": hist,\n",
        "                        \"time_elapsed\": time.time() - start_time\n",
        "                    }\n",
        "                    return delta_final, diagnostics\n",
        "\n",
        "        # keep same assignment to x_snap for minimal edits (harmless)\n",
        "        x_snap = x_curr.clone()\n",
        "\n",
        "    # finished all epochs\n",
        "    delta_final = x_curr.detach().cpu().numpy()\n",
        "    diagnostics = {\n",
        "        \"queries\": int(query_count),\n",
        "        \"stop_reason\": stop_reason or \"completed_epochs\",\n",
        "        \"history\": hist,\n",
        "        \"time_elapsed\": time.time() - start_time\n",
        "    }\n",
        "    if verbose:\n",
        "        print(\"Finished epochs; stop_reason:\", diagnostics[\"stop_reason\"], \"queries:\", diagnostics[\"queries\"])\n",
        "    return delta_final, diagnostics\n"
      ],
      "metadata": {
        "id": "Du7Z6ayRKUU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                # Output: (64, 14, 14)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64*14*14, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.conv(x)              # (B, 64, 14, 14)\n",
        "        z = z.view(z.size(0), -1)     # Flatten correctly\n",
        "        return self.fc(z)"
      ],
      "metadata": {
        "id": "QEgqFh0fLLW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST loading\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_mnist_cnn.pt\"))\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Lambda(lambda x: x - 0.5)\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
        "testset  = torchvision.datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader  = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False)\n",
        "\n",
        "# Training setup\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=5, gamma=0.5)\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in testloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x).argmax(1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNxk6pOVKUR7",
        "outputId": "09383b22-b834-4120-874b-442a7a324683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 510kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.55MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 12.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_full_mnist(model, testloader, attack_fn, max_samples=None):\n",
        "    \"\"\"\n",
        "    attack_fn(model, x0 (C,H,W), true_label) → (delta_flat, diagnostics)\n",
        "    Supports ANY batch size from the testloader.\n",
        "    \"\"\"\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    success = 0\n",
        "    distortions = []\n",
        "    queries_list = []\n",
        "    total = 0\n",
        "\n",
        "    for X, Y in tqdm(testloader, desc=\"Evaluating MNIST\"):\n",
        "\n",
        "        # Move whole batch to device\n",
        "        X = X.to(device)     # shape (B,1,28,28)\n",
        "        Y = Y.to(device)     # shape (B,)\n",
        "\n",
        "        # Clean predictions for whole batch\n",
        "        with torch.no_grad():\n",
        "            preds = model(X).argmax(1)        # shape (B,)\n",
        "\n",
        "        # Loop over each element in batch\n",
        "        batch_size = X.size(0)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            if preds[i].item() != Y[i].item():\n",
        "                continue   # skip misclassified samples\n",
        "\n",
        "            # Prepare CPU np array for attack\n",
        "            x_i_cpu = X[i].cpu().numpy()   # (1,28,28)\n",
        "            y_i_cpu = Y[i].cpu().item()\n",
        "\n",
        "            # Run attack\n",
        "            delta_flat, diag = attack_fn(model, x_i_cpu, y_i_cpu)\n",
        "            queries = diag[\"queries\"]\n",
        "\n",
        "            # Build adversarial sample\n",
        "            adv = x_i_cpu + delta_flat.reshape(1, 28, 28)\n",
        "            adv_t = torch.from_numpy(adv).float().unsqueeze(0).to(device)\n",
        "\n",
        "            # Predict adversarial label\n",
        "            with torch.no_grad():\n",
        "                adv_pred = model(adv_t).argmax(1).item()\n",
        "\n",
        "            total += 1\n",
        "            dist = np.linalg.norm(delta_flat)\n",
        "\n",
        "            if adv_pred != y_i_cpu:\n",
        "                success += 1\n",
        "                distortions.append(dist)\n",
        "                queries_list.append(queries)\n",
        "\n",
        "            if max_samples and total >= max_samples:\n",
        "                break\n",
        "\n",
        "        if max_samples and total >= max_samples:\n",
        "            break\n",
        "\n",
        "    success_rate = success / total if total > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"success_rate\": success_rate,\n",
        "        \"distortions\": distortions,\n",
        "        \"queries\": queries_list,\n",
        "        \"total_attacked\": total\n",
        "    }\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "#  Attack wrapper for the generalized VR–ZO–AdamM\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "def attack_wrapper(model):\n",
        "    def attack_fn(model, x0_CHW, true_label):\n",
        "        # x0_CHW: numpy array (C,H,W), e.g. (1,28,28)\n",
        "        delta_flat, diag = zo_adamm(\n",
        "            model_or_predict=model,\n",
        "            x0=x0_CHW,                      # no flattening\n",
        "            true_label=true_label,\n",
        "            mu=0.01,\n",
        "            q=64,\n",
        "            Q_ref=256,\n",
        "            inner_m=20,\n",
        "            epochs=5,\n",
        "            alpha=0.05,\n",
        "            constrained=True,\n",
        "            lb=-0.5,\n",
        "            ub=0.5,\n",
        "            verbose=False\n",
        "        )\n",
        "        return delta_flat, diag\n",
        "\n",
        "    return attack_fn\n",
        "\n",
        "\n",
        "attack_fn = attack_wrapper(model)"
      ],
      "metadata": {
        "id": "1D_xlu55KUJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HAlazC8iKT7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8JH4zsfJ-nk",
        "outputId": "21e11b49-a555-4475-b478-ef173ddbfef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.01, 'q': 64, 'alpha': 0.05, 'inner_m': 5, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [03:48<00:00,  5.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.997582107596212\n",
            "Avg distortion: 4.776084899902344\n",
            "Avg queries: 605.3046859220359\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.01, 'q': 64, 'alpha': 0.05, 'inner_m': 10, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [03:42<00:00,  5.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.998388071730808\n",
            "Avg distortion: 4.898564338684082\n",
            "Avg queries: 596.0034308779011\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.01, 'q': 64, 'alpha': 0.1, 'inner_m': 5, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [02:27<00:00,  3.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9982873262139835\n",
            "Avg distortion: 6.536474704742432\n",
            "Avg queries: 378.537995761429\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.01, 'q': 64, 'alpha': 0.1, 'inner_m': 10, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [02:29<00:00,  3.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.998791053798106\n",
            "Avg distortion: 6.540417194366455\n",
            "Avg queries: 379.4791204357474\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.01, 'q': 32, 'alpha': 0.05, 'inner_m': 5, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [03:28<00:00,  5.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9968768889784405\n",
            "Avg distortion: 5.231054782867432\n",
            "Avg queries: 366.8969176351693\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.01, 'q': 32, 'alpha': 0.05, 'inner_m': 10, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [03:19<00:00,  4.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9984888172476325\n",
            "Avg distortion: 5.473419666290283\n",
            "Avg queries: 351.8565230551912\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.01, 'q': 32, 'alpha': 0.1, 'inner_m': 5, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [02:12<00:00,  3.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9982873262139835\n",
            "Avg distortion: 7.227199554443359\n",
            "Avg queries: 219.408618427692\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.01, 'q': 32, 'alpha': 0.1, 'inner_m': 10, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [02:11<00:00,  3.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.998791053798106\n",
            "Avg distortion: 7.242759704589844\n",
            "Avg queries: 219.75035303611054\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.02, 'q': 64, 'alpha': 0.05, 'inner_m': 5, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [03:48<00:00,  5.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.997582107596212\n",
            "Avg distortion: 4.775692462921143\n",
            "Avg queries: 605.1874368814381\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.02, 'q': 64, 'alpha': 0.05, 'inner_m': 10, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [03:45<00:00,  5.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.998388071730808\n",
            "Avg distortion: 4.897448539733887\n",
            "Avg queries: 595.795156407669\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.02, 'q': 64, 'alpha': 0.1, 'inner_m': 5, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [02:29<00:00,  3.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9981865806971589\n",
            "Avg distortion: 6.536055088043213\n",
            "Avg queries: 378.34184497375855\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.02, 'q': 64, 'alpha': 0.1, 'inner_m': 10, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [02:30<00:00,  3.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9988917993149304\n",
            "Avg distortion: 6.539890289306641\n",
            "Avg queries: 379.60998487140694\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.02, 'q': 32, 'alpha': 0.05, 'inner_m': 5, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [03:26<00:00,  5.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9968768889784405\n",
            "Avg distortion: 5.23148250579834\n",
            "Avg queries: 366.93633148054573\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.02, 'q': 32, 'alpha': 0.05, 'inner_m': 10, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [03:17<00:00,  4.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9986903082812815\n",
            "Avg distortion: 5.4729228019714355\n",
            "Avg queries: 352.13961464743267\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.02, 'q': 32, 'alpha': 0.1, 'inner_m': 5, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [02:10<00:00,  3.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.998589562764457\n",
            "Avg distortion: 7.225176811218262\n",
            "Avg queries: 219.59140435835351\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.02, 'q': 32, 'alpha': 0.1, 'inner_m': 10, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [02:11<00:00,  3.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9990932903485795\n",
            "Avg distortion: 7.241096496582031\n",
            "Avg queries: 219.99193304426743\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.03, 'q': 64, 'alpha': 0.05, 'inner_m': 5, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [03:47<00:00,  5.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.997582107596212\n",
            "Avg distortion: 4.773733615875244\n",
            "Avg queries: 604.7705514037568\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.03, 'q': 64, 'alpha': 0.05, 'inner_m': 10, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [03:42<00:00,  5.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.998388071730808\n",
            "Avg distortion: 4.895926475524902\n",
            "Avg queries: 595.5868819374369\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.03, 'q': 64, 'alpha': 0.1, 'inner_m': 5, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [02:27<00:00,  3.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9981865806971589\n",
            "Avg distortion: 6.534821510314941\n",
            "Avg queries: 378.1856075898264\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.03, 'q': 64, 'alpha': 0.1, 'inner_m': 10, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [02:28<00:00,  3.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.998992544831755\n",
            "Avg distortion: 6.539707183837891\n",
            "Avg queries: 380.1180919725696\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.03, 'q': 32, 'alpha': 0.05, 'inner_m': 5, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [03:22<00:00,  5.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9967761434616159\n",
            "Avg distortion: 5.230449199676514\n",
            "Avg queries: 366.72377198302\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.03, 'q': 32, 'alpha': 0.05, 'inner_m': 10, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [03:14<00:00,  4.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9984888172476325\n",
            "Avg distortion: 5.470466613769531\n",
            "Avg queries: 351.6597719705378\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.03, 'q': 32, 'alpha': 0.1, 'inner_m': 5, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [02:08<00:00,  3.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.9984888172476325\n",
            "Avg distortion: 7.223358154296875\n",
            "Avg queries: 219.45615982241952\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n",
            "\n",
            "====================================\n",
            "Running hyperparameters: {'mu': 0.03, 'q': 32, 'alpha': 0.1, 'inner_m': 10, 'epochs': 3}\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MNIST: 100%|██████████| 40/40 [02:09<00:00,  3.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 0.999194035865404\n",
            "Avg distortion: 7.239182949066162\n",
            "Avg queries: 220.04184311353094\n",
            "✔ Logged results to mnist_zoadamm_hyperparam_results_1.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "# ---------------------------------------\n",
        "# Define search ranges\n",
        "# ---------------------------------------\n",
        "# hyper_space = {\n",
        "#     \"mu\": [0.0005, 0.001, 0.002, 0.003, 0.004, 0.005],\n",
        "#     \"q\": [4, 6, 8, 10],\n",
        "#     \"alpha\": [0.001, 0.002, 0.005],\n",
        "#     \"inner_m\": [5, 10],\n",
        "#     \"epochs\": [2, 3]\n",
        "# }\n",
        "    # \"mu\": [0.005, 0.01, 0.02, 0.03],\n",
        "hyper_space = {\n",
        "    \"mu\": [0.01, 0.02, 0.03],\n",
        "    \"q\": [64,32],\n",
        "    \"alpha\": [0.05, 0.1],\n",
        "    \"inner_m\": [5, 10],\n",
        "    \"epochs\": [3]\n",
        "}\n",
        "\n",
        "# Cartesian product of all hyperparameter combos\n",
        "keys = list(hyper_space.keys())\n",
        "search_list = list(itertools.product(*hyper_space.values()))\n",
        "\n",
        "# ---------------------------------------\n",
        "# CSV output file\n",
        "# ---------------------------------------\n",
        "csv_file = \"mnist_zoadamm_hyperparam_results_1.csv\"\n",
        "\n",
        "# Create CSV header\n",
        "header = keys + [\n",
        "    \"success_rate\",\n",
        "    \"avg_distortion\",\n",
        "    \"avg_queries\",\n",
        "    \"total_attacked\",\n",
        "    \"timestamp\"\n",
        "]\n",
        "\n",
        "# Start fresh\n",
        "with open(csv_file, \"w\", newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "\n",
        "# ---------------------------------------\n",
        "# Loop over combinations\n",
        "# ---------------------------------------\n",
        "for values in search_list:\n",
        "\n",
        "    params = dict(zip(keys, values))\n",
        "\n",
        "    print(\"\\n====================================\")\n",
        "    print(\"Running hyperparameters:\", params)\n",
        "    print(\"====================================\")\n",
        "\n",
        "    # Build attack_fn with these parameters\n",
        "    def attack_wrapper_hp(model):\n",
        "        def attack_fn(model, x0_CHW, true_label):\n",
        "            delta, diag = zo_adamm(\n",
        "                model_or_predict=model,\n",
        "                x0=x0_CHW,\n",
        "                true_label=true_label,\n",
        "                mu=params[\"mu\"],\n",
        "                q=params[\"q\"],\n",
        "                inner_m=params[\"inner_m\"],\n",
        "                epochs=params[\"epochs\"],\n",
        "                alpha=params[\"alpha\"],\n",
        "                Q_ref=256,\n",
        "                constrained=True,\n",
        "                lb=-1.0,\n",
        "                ub=1.0,\n",
        "                verbose=False\n",
        "            )\n",
        "            return delta, diag\n",
        "        return attack_fn\n",
        "\n",
        "    attack_fn_hp = attack_wrapper_hp(model)\n",
        "\n",
        "    # Evaluate\n",
        "    results = evaluate_full_mnist(\n",
        "        model=model,\n",
        "        testloader=testloader,\n",
        "        attack_fn=attack_fn_hp,\n",
        "        max_samples=None\n",
        "    )\n",
        "\n",
        "    success_rate   = results[\"success_rate\"]\n",
        "    avg_distortion = float(np.mean(results[\"distortions\"])) if results[\"distortions\"] else None\n",
        "    avg_queries    = float(np.mean(results[\"queries\"])) if results[\"queries\"] else None\n",
        "    total_attacked = results[\"total_attacked\"]\n",
        "\n",
        "    # Print metrics\n",
        "    print(\"Success rate:\", success_rate)\n",
        "    print(\"Avg distortion:\", avg_distortion)\n",
        "    print(\"Avg queries:\", avg_queries)\n",
        "    # ---------------------------------------\n",
        "    # Write row to CSV\n",
        "    # ---------------------------------------\n",
        "    row = list(values) + [\n",
        "        success_rate,\n",
        "        avg_distortion,\n",
        "        avg_queries,\n",
        "        total_attacked,\n",
        "        datetime.now().isoformat()\n",
        "    ]\n",
        "\n",
        "    with open(csv_file, \"a\", newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(row)\n",
        "\n",
        "    print(f\"✔ Logged results to {csv_file}\")\n"
      ]
    }
  ]
}