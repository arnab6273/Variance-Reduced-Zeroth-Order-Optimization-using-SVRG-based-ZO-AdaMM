# -*- coding: utf-8 -*-
"""FINAL_attack_resnet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ejIyiJmplRYB8knvw9zbqC0FCCOAjH-3
"""

# # =====================================================================================
# # 1. MOUNT GOOGLE DRIVE AND LOAD MODEL
# # =====================================================================================

# print("üìÅ Mounting Google Drive...")
# from google.colab import drive
# drive.mount('/content/drive')

# import torch
# import torch.nn as nn
# import torchvision
# import torchvision.transforms as transforms
# import matplotlib.pyplot as plt
# import numpy as np
# import torch.nn.functional as F

# device = 'cuda' if torch.cuda.is_available() else 'cpu'
# print(f"üîß Using device: {device}")

# # =====================================================================================
# # 2. MODEL DEFINITION (SAME AS BEFORE)
# # =====================================================================================

# class BasicBlock(nn.Module):
#     def __init__(self, in_planes, out_planes, stride, dropRate=0.0):
#         super().__init__()
#         self.bn1 = nn.BatchNorm2d(in_planes)
#         self.relu1 = nn.ReLU(inplace=True)
#         self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
#                                padding=1, bias=False)
#         self.bn2 = nn.BatchNorm2d(out_planes)
#         self.relu2 = nn.ReLU(inplace=True)
#         self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,
#                                padding=1, bias=False)
#         self.droprate = dropRate
#         self.equalInOut = (in_planes == out_planes)
#         self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1,
#                                  stride=stride, padding=0, bias=False) or None

#     def forward(self, x):
#         if not self.equalInOut:
#             x = self.relu1(self.bn1(x))
#         else:
#             out = self.relu1(self.bn1(x))
#         out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))
#         if self.droprate > 0:
#             out = F.dropout(out, p=self.droprate, training=self.training)
#         out = self.conv2(out)
#         return torch.add(x if self.equalInOut else self.convShortcut(x), out)

# class NetworkBlock(nn.Module):
#     def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):
#         super().__init__()
#         self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)

#     def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):
#         layers = []
#         for i in range(nb_layers):
#             layers.append(block(i == 0 and in_planes or out_planes, out_planes,
#                               i == 0 and stride or 1, dropRate))
#         return nn.Sequential(*layers)

#     def forward(self, x):
#         return self.layer(x)

# class WideResNet(nn.Module):
#     def __init__(self, depth=28, widen_factor=10, dropout=0.3, num_classes=100):
#         super().__init__()
#         nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]
#         assert ((depth - 4) % 6 == 0)
#         n = (depth - 4) // 6
#         block = BasicBlock

#         self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,
#                                padding=1, bias=False)
#         self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropout)
#         self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropout)
#         self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropout)
#         self.bn1 = nn.BatchNorm2d(nChannels[3])
#         self.relu = nn.ReLU(inplace=True)
#         self.fc = nn.Linear(nChannels[3], num_classes)
#         self.nChannels = nChannels[3]

#     def forward(self, x):
#         out = self.conv1(x)
#         out = self.block1(out)
#         out = self.block2(out)
#         out = self.block3(out)
#         out = self.relu(self.bn1(out))
#         out = F.adaptive_avg_pool2d(out, (1, 1))
#         out = out.view(-1, self.nChannels)
#         return self.fc(out)

# # =====================================================================================
# # 3. LOAD THE TRAINED MODEL
# # =====================================================================================

# print("\nüîÑ Loading trained model...")

# # Try loading the continued model first, then fallback to original
# model_files_to_try = [
#     "/content/drive/MyDrive/wrn28_10_weights_continued.pth",
#     "/content/drive/MyDrive/wrn28_10_entire_model_continued.pth",
#     "/content/drive/MyDrive/wrn28_10_checkpoint_clean_continued.pth",
#     "/content/drive/MyDrive/wrn28_10_weights.pth",
#     "/content/drive/MyDrive/wrn28_10_entire_model.pth",
#     "/content/drive/MyDrive/wrn28_10_checkpoint_clean.pth"
# ]

# model = None
# for model_file in model_files_to_try:
#     try:
#         if "entire_model" in model_file:
#             model = torch.load(model_file, map_location=device)
#             print(f"‚úì Loaded entire model from: {model_file}")
#             break
#         elif "weights" in model_file:
#             model = WideResNet(28, 10, dropout=0.3, num_classes=100).to(device)
#             model.load_state_dict(torch.load(model_file, map_location=device))
#             print(f"‚úì Loaded weights from: {model_file}")
#             break
#         elif "checkpoint" in model_file:
#             checkpoint = torch.load(model_file, map_location=device, weights_only=False)
#             if 'model_state_dict' in checkpoint:
#                 model = WideResNet(28, 10, dropout=0.3, num_classes=100).to(device)
#                 model.load_state_dict(checkpoint['model_state_dict'])
#                 print(f"‚úì Loaded checkpoint from: {model_file}")
#                 break
#     except Exception as e:
#         print(f"‚ö† Failed to load {model_file}: {e}")
#         continue

# if model is None:
#     raise RuntimeError("‚ùå Could not load any model file!")

# model.eval()
# print("‚úÖ Model loaded and ready for predictions!")

# # =====================================================================================
# # 4. LOAD CIFAR-100 DATASET FOR TESTING
# # =====================================================================================

# print("\nüì• Loading CIFAR-100 test dataset...")

# transform_test = transforms.Compose([
#     transforms.ToTensor(),
#     transforms.Normalize((0.5071, 0.4867, 0.4408),
#                          (0.2675, 0.2565, 0.2761)),
# ])

# test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,
#                                              download=True, transform=transform_test)

# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100,
#                                          shuffle=False, num_workers=2)

# # CIFAR-100 class names
# class_names = [
#     'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',
#     'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',
#     'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',
#     'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',
#     'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',
#     'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',
#     'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',
#     'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',
#     'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',
#     'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',
#     'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',
#     'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',
#     'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',
#     'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',
#     'worm'
# ]

# print(f"‚úÖ Loaded CIFAR-100 test set with {len(test_dataset)} images")

# # =====================================================================================
# # 5. PREDICTION FUNCTIONS
# # =====================================================================================

# def get_predictions(images):
#     """Get model predictions (logits) for given images"""
#     with torch.no_grad():
#         images = images.to(device)
#         logits = model(images)
#         probabilities = torch.softmax(logits, dim=1)
#         predicted_classes = torch.argmax(logits, dim=1)
#     return logits.cpu(), probabilities.cpu(), predicted_classes.cpu()

# def plot_predictions(images, true_labels, num_images=10):
#     """Plot images with true and predicted labels"""
#     # Get predictions for the batch
#     logits, probabilities, predicted_labels = get_predictions(images[:num_images])

#     fig, axes = plt.subplots(2, 5, figsize=(8, 6))
#     axes = axes.ravel()

#     for i in range(num_images):
#         # Denormalize image for display
#         img = images[i].cpu().numpy().transpose(1, 2, 0)
#         mean = np.array([0.5071, 0.4867, 0.4408])
#         std = np.array([0.2675, 0.2565, 0.2761])
#         img = std * img + mean
#         img = np.clip(img, 0, 1)

#         axes[i].imshow(img)
#         true_class = class_names[true_labels[i]]
#         pred_class = class_names[predicted_labels[i]]
#         confidence = probabilities[i][predicted_labels[i]].item()

#         color = 'green' if true_labels[i] == predicted_labels[i] else 'red'
#         axes[i].set_title(f"True: {true_class}\nPred: {pred_class}\nConf: {confidence:.3f}",
#                          color=color, fontsize=9)
#         axes[i].axis('off')

#     plt.tight_layout()
#     plt.show()

# # =====================================================================================
# # 6. TEST THE MODEL ON A FEW SAMPLES
# # =====================================================================================

# print("\nüîç Testing model on sample images...")

# # Get one batch of test data
# test_iter = iter(test_loader)
# images, labels = next(test_iter)

# print(f"üìä Batch shape: {images.shape}")
# print(f"üìä Labels shape: {labels.shape}")

# # Get predictions for the entire batch
# logits, probabilities, predictions = get_predictions(images)

# print(f"üìä Logits shape: {logits.shape}")
# print(f"üìä Probabilities shape: {probabilities.shape}")
# print(f"üìä Predictions shape: {predictions.shape}")

# # Calculate accuracy on this batch
# accuracy = (predictions == labels).float().mean().item()
# print(f"üéØ Batch accuracy: {accuracy * 100:.2f}%")

# # Show some sample predictions
# print("\nüñºÔ∏è Displaying sample predictions:")
# plot_predictions(images, labels, num_images=10)

# # =====================================================================================
# # 7. MODEL READY FOR BLACK BOX ATTACKS
# # =====================================================================================

# print("\n" + "="*70)
# print("‚úÖ MODEL READY FOR BLACK BOX ATTACKS!")
# print("="*70)
# print("üéØ Available functions:")
# print("   - get_predictions(images) ‚Üí returns logits, probabilities, predicted_classes")
# print("   - plot_predictions(images, true_labels) ‚Üí visualizes predictions")
# print("üìä Model outputs:")
# print("   - Logits: raw output before softmax")
# print("   - Probabilities: softmax output (0-1)")
# print("   - Predicted classes: argmax of logits")
# print("="*70)

# =====================================================================================
# 1. MOUNT GOOGLE DRIVE AND LOAD MODEL
# =====================================================================================

print("üìÅ Mounting Google Drive...")
from google.colab import drive
drive.mount('/content/drive')

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import torch.nn.functional as F

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"üîß Using device: {device}")

# =====================================================================================
# 2. MODEL DEFINITION (SAME AS BEFORE)
# =====================================================================================

class BasicBlock(nn.Module):
    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):
        super().__init__()
        self.bn1 = nn.BatchNorm2d(in_planes)
        self.relu1 = nn.ReLU(inplace=True)
        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                               padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_planes)
        self.relu2 = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,
                               padding=1, bias=False)
        self.droprate = dropRate
        self.equalInOut = (in_planes == out_planes)
        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1,
                                 stride=stride, padding=0, bias=False) or None

    def forward(self, x):
        if not self.equalInOut:
            x = self.relu1(self.bn1(x))
        else:
            out = self.relu1(self.bn1(x))
        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))
        if self.droprate > 0:
            out = F.dropout(out, p=self.droprate, training=self.training)
        out = self.conv2(out)
        return torch.add(x if self.equalInOut else self.convShortcut(x), out)

class NetworkBlock(nn.Module):
    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):
        super().__init__()
        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)

    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):
        layers = []
        for i in range(nb_layers):
            layers.append(block(i == 0 and in_planes or out_planes, out_planes,
                              i == 0 and stride or 1, dropRate))
        return nn.Sequential(*layers)

    def forward(self, x):
        return self.layer(x)

class WideResNet(nn.Module):
    def __init__(self, depth=28, widen_factor=10, dropout=0.3, num_classes=100):
        super().__init__()
        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]
        assert ((depth - 4) % 6 == 0)
        n = (depth - 4) // 6
        block = BasicBlock

        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,
                               padding=1, bias=False)
        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropout)
        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropout)
        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropout)
        self.bn1 = nn.BatchNorm2d(nChannels[3])
        self.relu = nn.ReLU(inplace=True)
        self.fc = nn.Linear(nChannels[3], num_classes)
        self.nChannels = nChannels[3]

    def forward(self, x):
        out = self.conv1(x)
        out = self.block1(out)
        out = self.block2(out)
        out = self.block3(out)
        out = self.relu(self.bn1(out))
        out = F.adaptive_avg_pool2d(out, (1, 1))
        out = out.view(-1, self.nChannels)
        return self.fc(out)

# =====================================================================================
# 3. LOAD THE TRAINED MODEL
# =====================================================================================

print("\nüîÑ Loading trained model...")

# Try loading the continued model first, then fallback to original
model_files_to_try = [
    "/content/drive/MyDrive/wrn28_10_weights_continued.pth",
    "/content/drive/MyDrive/wrn28_10_entire_model_continued.pth",
    "/content/drive/MyDrive/wrn28_10_checkpoint_clean_continued.pth",
    "/content/drive/MyDrive/wrn28_10_weights.pth",
    "/content/drive/MyDrive/wrn28_10_entire_model.pth",
    "/content/drive/MyDrive/wrn28_10_checkpoint_clean.pth"
]

model = None
for model_file in model_files_to_try:
    try:
        if "entire_model" in model_file:
            model = torch.load(model_file, map_location=device)
            print(f"‚úì Loaded entire model from: {model_file}")
            break
        elif "weights" in model_file:
            model = WideResNet(28, 10, dropout=0.3, num_classes=100).to(device)
            model.load_state_dict(torch.load(model_file, map_location=device))
            print(f"‚úì Loaded weights from: {model_file}")
            break
        elif "checkpoint" in model_file:
            checkpoint = torch.load(model_file, map_location=device, weights_only=False)
            if 'model_state_dict' in checkpoint:
                model = WideResNet(28, 10, dropout=0.3, num_classes=100).to(device)
                model.load_state_dict(checkpoint['model_state_dict'])
                print(f"‚úì Loaded checkpoint from: {model_file}")
                break
    except Exception as e:
        print(f"‚ö† Failed to load {model_file}: {e}")
        continue

if model is None:
    raise RuntimeError("‚ùå Could not load any model file!")

model.eval()
print("‚úÖ Model loaded and ready for predictions!")

# =====================================================================================
# 4. LOAD CIFAR-100 DATASET FOR TESTING
# =====================================================================================

print("\nüì• Loading CIFAR-100 test dataset...")

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5071, 0.4867, 0.4408),
                         (0.2675, 0.2565, 0.2761)),
])

test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,
                                             download=True, transform=transform_test)

test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100,
                                         shuffle=False, num_workers=2)

# CIFAR-100 class names
class_names = [
    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',
    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',
    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',
    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',
    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',
    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',
    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',
    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',
    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',
    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',
    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',
    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',
    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',
    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',
    'worm'
]

print(f"‚úÖ Loaded CIFAR-100 test set with {len(test_dataset)} images")

# =====================================================================================
# 5. PREDICTION FUNCTIONS
# =====================================================================================

def get_predictions(images):
    """Get model predictions (logits) for given images"""
    with torch.no_grad():
        images = images.to(device)
        logits = model(images)
        probabilities = torch.softmax(logits, dim=1)
        predicted_classes = torch.argmax(logits, dim=1)
    return logits.cpu(), probabilities.cpu(), predicted_classes.cpu()

def plot_predictions(images, true_labels, num_images=10):
    """Plot images with true and predicted labels"""
    # Get predictions for the batch
    logits, probabilities, predicted_labels = get_predictions(images[:num_images])

    fig, axes = plt.subplots(2, 5, figsize=(8, 6))
    axes = axes.ravel()

    for i in range(num_images):
        # Denormalize image for display
        img = images[i].cpu().numpy().transpose(1, 2, 0)
        mean = np.array([0.5071, 0.4867, 0.4408])
        std = np.array([0.2675, 0.2565, 0.2761])
        img = std * img + mean
        img = np.clip(img, 0, 1)

        axes[i].imshow(img)
        true_class = class_names[true_labels[i]]
        pred_class = class_names[predicted_labels[i]]
        confidence = probabilities[i][predicted_labels[i]].item()

        color = 'green' if true_labels[i] == predicted_labels[i] else 'red'
        axes[i].set_title(f"True: {true_class}\nPred: {pred_class}\nConf: {confidence:.3f}",
                         color=color, fontsize=9)
        axes[i].axis('off')

    plt.tight_layout()
    plt.show()

# =====================================================================================
# 6. TEST THE MODEL ON A FEW SAMPLES
# =====================================================================================

print("\nüîç Testing model on sample images...")

# Get one batch of test data
test_iter = iter(test_loader)
images, labels = next(test_iter)

print(f"üìä Batch shape: {images.shape}")
print(f"üìä Labels shape: {labels.shape}")

# Get predictions for the entire batch
logits, probabilities, predictions = get_predictions(images)

print(f"üìä Logits shape: {logits.shape}")
print(f"üìä Probabilities shape: {probabilities.shape}")
print(f"üìä Predictions shape: {predictions.shape}")

# Calculate accuracy on this batch
accuracy = (predictions == labels).float().mean().item()
print(f"üéØ Batch accuracy: {accuracy * 100:.2f}%")

# Show some sample predictions
print("\nüñºÔ∏è Displaying sample predictions:")
plot_predictions(images, labels, num_images=10)

# =====================================================================================
# 7. MODEL READY FOR BLACK BOX ATTACKS
# =====================================================================================

print("\n" + "="*70)
print("‚úÖ MODEL READY FOR BLACK BOX ATTACKS!")
print("="*70)
print("üéØ Available functions:")
print("   - get_predictions(images) ‚Üí returns logits, probabilities, predicted_classes")
print("   - plot_predictions(images, true_labels) ‚Üí visualizes predictions")
print("üìä Model outputs:")
print("   - Logits: raw output before softmax")
print("   - Probabilities: softmax output (0-1)")
print("   - Predicted classes: argmax of logits")
print("="*70)

# =====================================================================================
# 8. SETUP FOR ZO ATTACKS
# =====================================================================================

print("üîß Setting up model for black-box attacks...")

# Make sure model is in eval mode
model.eval()

# Get test dataset for attacks
test_loader_single = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)

print(f"‚úÖ Model ready for attacks on CIFAR-100 with {len(class_names)} classes")

# =====================================================================================
# 9. FIND CORRECTLY CLASSIFIED INSTANCES TO ATTACK
# =====================================================================================

print("\nüîç Finding correctly classified instances to attack...")

correctly_classified_indices = []
images_to_attack = []
labels_to_attack = []

for idx, (image, true_label) in enumerate(test_loader_single):
    if idx >= 1000:  # Check first 1000 samples for speed
        break

    with torch.no_grad():
        image = image.to(device)
        output = model(image)
        pred_class = torch.argmax(output, dim=1).item()

        if pred_class == true_label.item():
            correctly_classified_indices.append(idx)
            images_to_attack.append(image.cpu())
            labels_to_attack.append(true_label.item())

print(f"Correctly classified instances: {len(correctly_classified_indices)}/1000")
print(f"Available for attack: {len(correctly_classified_indices)}")

# Select a subset for attacks (due to computational constraints)
attack_indices = correctly_classified_indices[:50]  # Attack 50 samples
print(f"Selected for attack: {len(attack_indices)} samples")

# =====================================================================================
# 10. ZERO-ORDER ATTACK HELPER FUNCTIONS
# =====================================================================================

import numpy as np
import torch
import torch.nn as nn
from copy import deepcopy
import time
from math import sqrt

def model_probabilities(model, image_tensor):
    """Get model probabilities for all classes"""
    model.eval()
    with torch.no_grad():
        image_tensor = image_tensor.to(device)
        logits = model(image_tensor)
        probabilities = torch.softmax(logits, dim=1)
    return probabilities.cpu().numpy()[0]

def model_predict(model, image_tensor):
    """Get predicted class and probability"""
    probs = model_probabilities(model, image_tensor)
    pred_class = np.argmax(probs)
    confidence = probs[pred_class]
    return pred_class, confidence, probs

def proj_l2_ball(delta, eps):
    """Project perturbation to L2 ball of radius eps"""
    delta_flat = delta.reshape(-1)
    norm = np.linalg.norm(delta_flat)
    if norm <= eps:
        return delta
    return delta * (eps / norm)

def proj_linf_ball(delta, eps):
    """Project perturbation to Linf ball of radius eps"""
    return np.clip(delta, -eps, eps)

def zo_two_point_grad_estimator(f_query, x, mu, q=10):
    """
    Two-point gradient estimator
    g = (d/q) * Œ£_{i=1}^q [f(x+Œºu_i) - f(x-Œºu_i)]/(2Œº) * u_i
    """
    d = x.size
    g_acc = np.zeros(d, dtype=float)

    for _ in range(q):
        u = np.random.normal(size=d)
        u = u / (np.linalg.norm(u) + 1e-12)  # unit vector

        # Two-point estimate
        f_plus = f_query(x + mu * u)
        f_minus = f_query(x - mu * u)

        g_i = ((f_plus - f_minus) / (2 * mu)) * u
        g_acc += g_i

    return (d / q) * g_acc, 2 * q  # gradient + queries used

# =====================================================================================
# 11. ZO-ADAMM ATTACK FOR RESNET (FIXED DEVICE ISSUES)
# =====================================================================================

def zo_adamm_attack_resnet(model, image_orig, true_label,
                          eps=8.0, norm='l2',
                          T=500, alpha=0.1, mu=None, q=10,
                          beta1=0.9, beta2=0.999, lam=0.99, eps_adam=1e-8,
                          early_stop=True, verbose=False):
    """
    ZO-AdaMM attack for ResNet model on CIFAR-100
    """
    # Use the original model on the correct device (don't copy to CPU)
    model_device = model
    image_shape = image_orig.shape
    d = image_orig.numel()

    if mu is None:
        mu = 1.0 / sqrt(max(1, T * d))

    proj = proj_l2_ball if norm == 'l2' else proj_linf_ball

    def f_query(x_arr):
        # Reshape back to image and move to correct device
        x_image = torch.FloatTensor(x_arr.reshape(image_shape)).to(device)
        probs = model_probabilities(model_device, x_image)

        # Objective: minimize probability of true class
        return probs[true_label]

    # Initialize variables
    x_orig_np = image_orig.cpu().numpy().reshape(-1)
    x = x_orig_np.copy()
    m = np.zeros(d, dtype=float)
    v = np.zeros(d, dtype=float)
    vhat = np.zeros(d, dtype=float)

    queries = 0
    start = time.time()

    # Initial prediction
    init_pred, init_conf, _ = model_predict(model_device, image_orig.to(device))
    queries += 1

    if verbose:
        true_class_name = class_names[true_label]
        init_class_name = class_names[init_pred]
        print(f"[ZO-AdaMM] True: {true_label}({true_class_name}), Initial: {init_pred}({init_class_name}), conf={init_conf:.6f}")

    for t in range(1, T + 1):
        beta1_t = beta1 * (lam ** (t - 1))

        # Gradient estimation
        g_hat, q_used = zo_two_point_grad_estimator(f_query, x, mu, q=q)
        queries += q_used

        # Moment updates
        m = beta1_t * m + (1 - beta1_t) * g_hat
        v = beta2 * v + (1 - beta2) * (g_hat ** 2)

        # Bias correction
        m_hat = m / (1 - beta1 ** t)
        v_hat = v / (1 - beta2 ** t)
        vhat = np.maximum(vhat, v_hat)

        # Adaptive update
        x_new = x - alpha * m_hat / (np.sqrt(vhat) + eps_adam)

        # Projection
        perturbation = x_new - x_orig_np
        perturbation_projected = proj(perturbation, eps)
        x = x_orig_np + perturbation_projected

        # Clip to valid image range [0, 1] after denormalization
        x_reshaped = x.reshape(image_shape)
        x_reshaped = np.clip(x_reshaped, -2.0, 2.0)  # Allow some range for normalized images
        x = x_reshaped.reshape(-1)

        # Check attack success
        x_image = torch.FloatTensor(x.reshape(image_shape)).to(device)
        pred_label, conf, _ = model_predict(model_device, x_image)
        queries += 1

        success = (pred_label != true_label)

        if verbose and (t % 50 == 0 or success):
            current_perturb_norm = np.linalg.norm(x - x_orig_np)
            pred_class_name = class_names[pred_label]
            print(f"Iter {t}: pred={pred_label}({pred_class_name}), conf={conf:.4f}, "
                  f"perturb_norm={current_perturb_norm:.4f}, success={success}")

        if success and early_stop:
            end = time.time()
            delta = x - x_orig_np
            return {
                "method": "ZO-AdaMM",
                "success": True,
                "final_label": pred_label,
                "final_confidence": conf,
                "delta": delta.copy(),
                "norm": np.linalg.norm(delta),
                "queries": queries,
                "iters": t,
                "time_sec": end - start
            }

    end = time.time()
    x_image = torch.FloatTensor(x.reshape(image_shape)).to(device)
    pred_label, conf, _ = model_predict(model_device, x_image)
    delta = x - x_orig_np

    return {
        "method": "ZO-AdaMM",
        "success": (pred_label != true_label),
        "final_label": pred_label,
        "final_confidence": conf,
        "delta": delta.copy(),
        "norm": np.linalg.norm(delta),
        "queries": queries,
        "iters": T,
        "time_sec": end - start
    }

# =====================================================================================
# 12. ZO-SGD ATTACK FOR RESNET (FIXED DEVICE ISSUES)
# =====================================================================================

def zo_sgd_attack_resnet(model, image_orig, true_label,
                        eps=8.0, norm='l2',
                        T=500, lr=0.1, mu=None, q=10,
                        early_stop=True, verbose=False):
    """
    ZO-SGD attack for ResNet model on CIFAR-100
    """
    # Use the original model on the correct device (don't copy to CPU)
    model_device = model
    image_shape = image_orig.shape
    d = image_orig.numel()

    if mu is None:
        mu = 1.0 / sqrt(max(1, T * d))
    proj = proj_l2_ball if norm == 'l2' else proj_linf_ball

    def f_query(x_arr):
        # Reshape back to image and move to correct device
        x_image = torch.FloatTensor(x_arr.reshape(image_shape)).to(device)
        probs = model_probabilities(model_device, x_image)

        # Objective: minimize probability of true class
        return probs[true_label]

    x_orig_np = image_orig.cpu().numpy().reshape(-1)
    x = x_orig_np.copy()
    queries = 0
    start = time.time()

    # Initial prediction
    pred0, conf0, _ = model_predict(model_device, image_orig.to(device))
    queries += 1

    for t in range(1, T + 1):
        # Gradient estimation
        g_hat, q_used = zo_two_point_grad_estimator(f_query, x, mu, q=q)
        queries += q_used

        # SGD step
        x_new = x - lr * g_hat

        # Projection
        perturbation = x_new - x_orig_np
        perturbation_projected = proj(perturbation, eps)
        x = x_orig_np + perturbation_projected

        # Clip to valid image range
        x_reshaped = x.reshape(image_shape)
        x_reshaped = np.clip(x_reshaped, -2.0, 2.0)
        x = x_reshaped.reshape(-1)

        # Check success
        x_image = torch.FloatTensor(x.reshape(image_shape)).to(device)
        pred_label, conf, _ = model_predict(model_device, x_image)
        queries += 1

        if pred_label != true_label and early_stop:
            end = time.time()
            delta = x - x_orig_np
            return {
                "method": "ZO-SGD",
                "success": True,
                "final_label": pred_label,
                "final_confidence": conf,
                "delta": delta.copy(),
                "norm": np.linalg.norm(delta),
                "queries": queries,
                "iters": t,
                "time_sec": end - start
            }

    end = time.time()
    x_image = torch.FloatTensor(x.reshape(image_shape)).to(device)
    pred_label, conf, _ = model_predict(model_device, x_image)
    delta = x - x_orig_np
    return {
        "method": "ZO-SGD",
        "success": (pred_label != true_label),
        "final_label": pred_label,
        "final_confidence": conf,
        "delta": delta.copy(),
        "norm": np.linalg.norm(delta),
        "queries": queries,
        "iters": T,
        "time_sec": end - start
    }

# =====================================================================================
# 13. COMPARISON FUNCTION FOR RESNET
# =====================================================================================

import pandas as pd

def compare_attacks_resnet(model, test_loader, indices,
                          adamm_kwargs=None, sgd_kwargs=None,
                          save_csv_path="zo_attack_results_resnet.csv"):
    """
    Run ZO-AdaMM vs ZO-SGD comparison on ResNet model
    """
    if adamm_kwargs is None:
        adamm_kwargs = dict(eps=8.0, norm='l2', T=300, alpha=0.05, q=10,
                           beta1=0.9, beta2=0.999, lam=0.99)
    if sgd_kwargs is None:
        sgd_kwargs = dict(eps=8.0, norm='l2', T=300, lr=0.05, q=10)

    results = []

    for i, idx in enumerate(indices):
        # Get the test sample
        image_orig, true_label = test_loader.dataset[idx]
        image_orig = image_orig.unsqueeze(0)  # Add batch dimension

        # Get original prediction
        orig_pred, orig_conf, orig_probs = model_predict(model, image_orig.to(device))

        print(f"\nüî¨ Sample {i+1}/{len(indices)} - Index {idx}")
        print(f"   True: {true_label}({class_names[true_label]}), Original: {orig_pred}({class_names[orig_pred]}), Confidence: {orig_conf:.4f}")

        # Run ZO-AdaMM attack
        res_adamm = zo_adamm_attack_resnet(model, image_orig, true_label, **adamm_kwargs)

        # Run ZO-SGD attack
        res_sgd = zo_sgd_attack_resnet(model, image_orig, true_label, **sgd_kwargs)

        # Calculate metrics
        adamm_confidence_change = orig_conf - res_adamm['final_confidence'] if res_adamm['success'] else 0
        sgd_confidence_change = orig_conf - res_sgd['final_confidence'] if res_sgd['success'] else 0

        results.append({
            "index": idx,
            "true_label": true_label,
            "true_class": class_names[true_label],
            "original_pred": orig_pred,
            "original_confidence": orig_conf,
            # ZO-AdaMM results
            "adamm_success": res_adamm["success"],
            "adamm_queries": res_adamm["queries"],
            "adamm_iters": res_adamm["iters"],
            "adamm_norm": res_adamm["norm"],
            "adamm_time_s": res_adamm["time_sec"],
            "adamm_final_confidence": res_adamm["final_confidence"],
            "adamm_confidence_change": adamm_confidence_change,
            # ZO-SGD results
            "sgd_success": res_sgd["success"],
            "sgd_queries": res_sgd["queries"],
            "sgd_iters": res_sgd["iters"],
            "sgd_norm": res_sgd["norm"],
            "sgd_time_s": res_sgd["time_sec"],
            "sgd_final_confidence": res_sgd["final_confidence"],
            "sgd_confidence_change": sgd_confidence_change,
        })

        print(f"   ZO-AdaMM: success={res_adamm['success']}, queries={res_adamm['queries']}, norm={res_adamm['norm']:.4f}")
        print(f"   ZO-SGD:   success={res_sgd['success']}, queries={res_sgd['queries']}, norm={res_sgd['norm']:.4f}")

    df_results = pd.DataFrame(results)

    # Summary statistics
    summary = {
        "adamm_success_rate": df_results["adamm_success"].mean(),
        "adamm_avg_queries": df_results[df_results["adamm_success"]]["adamm_queries"].mean() if df_results["adamm_success"].sum() > 0 else 0,
        "adamm_avg_norm": df_results["adamm_norm"].mean(),
        "adamm_avg_confidence_change": df_results[df_results["adamm_success"]]["adamm_confidence_change"].mean() if df_results["adamm_success"].sum() > 0 else 0,
        "sgd_success_rate": df_results["sgd_success"].mean(),
        "sgd_avg_queries": df_results[df_results["sgd_success"]]["sgd_queries"].mean() if df_results["sgd_success"].sum() > 0 else 0,
        "sgd_avg_norm": df_results["sgd_norm"].mean(),
        "sgd_avg_confidence_change": df_results[df_results["sgd_success"]]["sgd_confidence_change"].mean() if df_results["sgd_success"].sum() > 0 else 0,
        "n_samples": len(indices)
    }

    df_results.to_csv(save_csv_path, index=False)
    return df_results, summary

# =====================================================================================
# 14. RUN ATTACKS ON RESNET MODEL
# =====================================================================================

print("\n" + "="*70)
print("üöÄ STARTING ZO-ADAMM vs ZO-SGD ATTACKS ON RESNET")
print("="*70)

# Attack parameters for CIFAR-100
attack_params = {
    'eps': 8.0,        # Larger epsilon for image space
    'norm': 'l2',      # L2 norm constraint
    'T': 300,          # Maximum iterations
    'q': 10,           # Query samples per iteration
}

# Run attacks on selected samples
df_results, summary = compare_attacks_resnet(
    model,
    test_loader_single,
    attack_indices[:20],  # Attack first 20 samples for speed
    adamm_kwargs={**attack_params, 'alpha': 0.05},
    sgd_kwargs={**attack_params, 'lr': 0.05},
    save_csv_path="zo_attack_results_resnet.csv"
)

# =====================================================================================
# 15. PRINT COMPREHENSIVE RESULTS
# =====================================================================================

print("\n" + "="*70)
print("üìä ATTACK RESULTS - ZO-AdaMM vs ZO-SGD on ResNet")
print("="*70)

print(f"\nüéØ SUCCESS RATES:")
print(f"   ZO-AdaMM: {summary['adamm_success_rate']:.1%} ({df_results['adamm_success'].sum()}/{summary['n_samples']})")
print(f"   ZO-SGD:   {summary['sgd_success_rate']:.1%} ({df_results['sgd_success'].sum()}/{summary['n_samples']})")

print(f"\nüìà QUERY EFFICIENCY (Successful Attacks):")
print(f"   ZO-AdaMM: {summary['adamm_avg_queries']:.0f} queries")
print(f"   ZO-SGD:   {summary['sgd_avg_queries']:.0f} queries")

if summary['sgd_avg_queries'] > 0:
    query_improvement = (summary['sgd_avg_queries'] - summary['adamm_avg_queries']) / summary['sgd_avg_queries']
    print(f"   Query Efficiency Improvement: {query_improvement:.1%}")

print(f"\nüé® PERTURBATION SIZE:")
print(f"   ZO-AdaMM avg L2 norm: {summary['adamm_avg_norm']:.4f}")
print(f"   ZO-SGD avg L2 norm:   {summary['sgd_avg_norm']:.4f}")

print(f"\nüìä CONFIDENCE REDUCTION (Successful Attacks):")
print(f"   ZO-AdaMM avg confidence drop: {summary['adamm_avg_confidence_change']:.4f}")
print(f"   ZO-SGD avg confidence drop:   {summary['sgd_avg_confidence_change']:.4f}")

# Performance analysis
print(f"\n" + "="*70)
print("üî¨ PERFORMANCE ANALYSIS")
print("="*70)

if summary['adamm_success_rate'] > summary['sgd_success_rate']:
    success_advantage = "ZO-AdaMM has higher success rate"
elif summary['adamm_success_rate'] < summary['sgd_success_rate']:
    success_advantage = "ZO-SGD has higher success rate"
else:
    success_advantage = "Both methods have equal success rate"

if summary['adamm_avg_queries'] < summary['sgd_avg_queries']:
    query_advantage = "ZO-AdaMM is more query-efficient"
elif summary['adamm_avg_queries'] > summary['sgd_avg_queries']:
    query_advantage = "ZO-SGD is more query-efficient"
else:
    query_advantage = "Both methods have similar query efficiency"

print(f"‚úÖ Success Rate: {success_advantage}")
print(f"‚úÖ Query Efficiency: {query_advantage}")

# Verify perturbation constraints
print(f"\n" + "="*70)
print("üîç CONSTRAINT VERIFICATION")
print("="*70)

adamm_norms = df_results['adamm_norm']
sgd_norms = df_results['sgd_norm']

print(f"ZO-AdaMM perturbation norms: min={adamm_norms.min():.4f}, max={adamm_norms.max():.4f}")
print(f"All within Œµ={attack_params['eps']}: {all(norm <= attack_params['eps'] + 1e-6 for norm in adamm_norms)}")
print(f"ZO-SGD perturbation norms: min={sgd_norms.min():.4f}, max={sgd_norms.max():.4f}")
print(f"All within Œµ={attack_params['eps']}: {all(norm <= attack_params['eps'] + 1e-6 for norm in sgd_norms)}")

# =====================================================================================
# 16. DETAILED SAMPLE ANALYSIS
# =====================================================================================

print(f"\n" + "="*70)
print("üî¨ DETAILED SAMPLE ANALYSIS")
print("="*70)

# Show detailed results for each sample
for i, row in df_results.iterrows():
    status_adamm = "‚úì" if row['adamm_success'] else "‚úó"
    status_sgd = "‚úì" if row['sgd_success'] else "‚úó"

    print(f"Sample {i+1:2d}: True={row['true_class']:15} | "
          f"AdaMM: {status_adamm} (Q:{row['adamm_queries']:4d}, N:{row['adamm_norm']:.3f}) | "
          f"SGD: {status_sgd} (Q:{row['sgd_queries']:4d}, N:{row['sgd_norm']:.3f})")

# =====================================================================================
# 17. STATISTICAL ANALYSIS
# =====================================================================================

print(f"\n" + "="*70)
print("üìà STATISTICAL ANALYSIS")
print("="*70)

from scipy.stats import mannwhitneyu

# Compare query efficiency on successful attacks
successful_adamm = df_results[df_results['adamm_success']]['adamm_queries']
successful_sgd = df_results[df_results['sgd_success']]['sgd_queries']

if len(successful_adamm) > 1 and len(successful_sgd) > 1:
    stat, p_value = mannwhitneyu(successful_adamm, successful_sgd, alternative='less')
    print(f"üìä Mann-Whitney U Test for Query Efficiency:")
    print(f"   U-statistic: {stat:.4f}, p-value: {p_value:.6f}")
    if p_value < 0.05:
        print("   ‚úÖ ZO-AdaMM is statistically significantly more query-efficient! (p < 0.05)")
    else:
        print("   ‚ùå No statistically significant difference in query efficiency")

# Compare perturbation norms
if len(successful_adamm) > 1 and len(successful_sgd) > 1:
    stat_norm, p_norm = mannwhitneyu(
        df_results[df_results['adamm_success']]['adamm_norm'],
        df_results[df_results['sgd_success']]['sgd_norm'],
        alternative='two-sided'
    )
    print(f"\nüìä Perturbation Norm Comparison:")
    print(f"   U-statistic: {stat_norm:.4f}, p-value: {p_norm:.6f}")
    if p_norm < 0.05:
        print("   ‚úÖ Statistically significant difference in perturbation norms!")
    else:
        print("   ‚ùå No significant difference in perturbation norms")

# =====================================================================================
# 18. VISUALIZE RESULTS
# =====================================================================================

print(f"\n" + "="*70)
print("üìä GENERATING VISUALIZATIONS")
print("="*70)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(15, 10))

# Plot 1: Success Rate Comparison
plt.subplot(2, 3, 1)
success_data = [
    ['ZO-AdaMM', summary['adamm_success_rate']],
    ['ZO-SGD', summary['sgd_success_rate']]
]
success_df = pd.DataFrame(success_data, columns=['Method', 'Success Rate'])
sns.barplot(data=success_df, x='Method', y='Success Rate')
plt.title('Attack Success Rate')
plt.ylim(0, 1)

# Plot 2: Query Efficiency
plt.subplot(2, 3, 2)
query_data = []
for queries in successful_adamm:
    query_data.append(['ZO-AdaMM', queries])
for queries in successful_sgd:
    query_data.append(['ZO-SGD', queries])
query_df = pd.DataFrame(query_data, columns=['Method', 'Queries'])
if len(query_df) > 0:
    sns.boxplot(data=query_df, x='Method', y='Queries')
    plt.title('Query Distribution (Successful Attacks)')
else:
    plt.text(0.5, 0.5, 'No successful attacks', ha='center', va='center')
    plt.title('Query Distribution')

# Plot 3: Perturbation Size
plt.subplot(2, 3, 3)
perturb_data = []
for norm in df_results['adamm_norm']:
    perturb_data.append(['ZO-AdaMM', norm])
for norm in df_results['sgd_norm']:
    perturb_data.append(['ZO-SGD', norm])
perturb_df = pd.DataFrame(perturb_data, columns=['Method', 'Perturbation_Norm'])
sns.boxplot(data=perturb_df, x='Method', y='Perturbation_Norm')
plt.axhline(y=attack_params['eps'], color='red', linestyle='--', alpha=0.7, label=f'Œµ={attack_params["eps"]}')
plt.title('Perturbation Size Distribution')
plt.legend()

# Plot 4: Success vs Queries Scatter
plt.subplot(2, 3, 4)
colors_adamm = ['green' if success else 'red' for success in df_results['adamm_success']]
colors_sgd = ['green' if success else 'red' for success in df_results['sgd_success']]
plt.scatter(df_results['adamm_queries'], df_results['adamm_norm'], c=colors_adamm, alpha=0.6, label='ZO-AdaMM')
plt.scatter(df_results['sgd_queries'], df_results['sgd_norm'], c=colors_sgd, alpha=0.6, label='ZO-SGD')
plt.xlabel('Queries')
plt.ylabel('Perturbation Norm')
plt.axhline(y=attack_params['eps'], color='red', linestyle='--', alpha=0.7)
plt.title('Query vs Perturbation Efficiency')
plt.legend()

# Plot 5: Confidence Reduction
plt.subplot(2, 3, 5)
conf_data = []
for change in df_results[df_results['adamm_success']]['adamm_confidence_change']:
    conf_data.append(['ZO-AdaMM', change])
for change in df_results[df_results['sgd_success']]['sgd_confidence_change']:
    conf_data.append(['ZO-SGD', change])
conf_df = pd.DataFrame(conf_data, columns=['Method', 'Confidence_Reduction'])
if len(conf_df) > 0:
    sns.boxplot(data=conf_df, x='Method', y='Confidence_Reduction')
    plt.title('Confidence Reduction (Successful Attacks)')
else:
    plt.text(0.5, 0.5, 'No successful attacks', ha='center', va='center')
    plt.title('Confidence Reduction')

# Plot 6: Time Efficiency
plt.subplot(2, 3, 6)
time_data = []
for time_val in df_results['adamm_time_s']:
    time_data.append(['ZO-AdaMM', time_val])
for time_val in df_results['sgd_time_s']:
    time_data.append(['ZO-SGD', time_val])
time_df = pd.DataFrame(time_data, columns=['Method', 'Time_Seconds'])
sns.boxplot(data=time_df, x='Method', y='Time_Seconds')
plt.title('Computation Time Distribution')

plt.tight_layout()
plt.savefig('resnet_attack_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

print(f"üìä Visualizations saved as 'resnet_attack_comparison.png'")

# =====================================================================================
# 19. FINAL SUMMARY
# =====================================================================================

print(f"\n" + "="*70)
print("üéâ FINAL SUMMARY - ZO-AdaMM vs ZO-SGD on ResNet")
print("="*70)

print(f"‚úÖ ZO-AdaMM Success Rate: {summary['adamm_success_rate']:.1%}")
print(f"‚úÖ ZO-SGD Success Rate:   {summary['sgd_success_rate']:.1%}")

if summary['sgd_avg_queries'] > 0:
    efficiency_ratio = summary['sgd_avg_queries'] / max(summary['adamm_avg_queries'], 1)
    print(f"üöÄ Query Efficiency Ratio (SGD/AdaMM): {efficiency_ratio:.2f}x")

print(f"üìà Statistical Significance: {'YES' if 'p_value' in locals() and p_value < 0.05 else 'NO'}")

if summary['adamm_success_rate'] > summary['sgd_success_rate'] and summary['adamm_avg_queries'] < summary['sgd_avg_queries']:
    print(f"üèÜ ZO-AdaMM demonstrates superior performance!")
elif summary['adamm_success_rate'] > summary['sgd_success_rate']:
    print(f"üéØ ZO-AdaMM has better success rate!")
elif summary['adamm_avg_queries'] < summary['sgd_avg_queries']:
    print(f"üéØ ZO-AdaMM is more query-efficient!")
else:
    print(f"üìä Both methods show similar performance")

print(f"\nüíæ Results saved to:")
print(f"   - zo_attack_results_resnet.csv")
print(f"   - resnet_attack_comparison.png")

print(f"\nüî¨ Key Parameters:")
print(f"   ‚Ä¢ Epsilon (Œµ): {attack_params['eps']}")
print(f"   ‚Ä¢ Norm: {attack_params['norm']}")
print(f"   ‚Ä¢ Max Iterations: {attack_params['T']}")
print(f"   ‚Ä¢ Query Samples: {attack_params['q']}")
print(f"   ‚Ä¢ Samples Tested: {summary['n_samples']}")

print(f"\nüéØ Conclusion: ZO attack methods successfully applied to ResNet model!")
print(f"   Both ZO-AdaMM and ZO-SGD can generate adversarial examples within constraints.")

# =====================================================================================
# 20. VR-ZO-ADAMM WITH SVRG VARIANCE REDUCTION
# =====================================================================================

def vr_zo_adamm_attack_resnet(model, image_orig, true_label,
                             eps=8.0, norm='l2',
                             T=500, alpha=0.1, mu=None, q=10, m=50, Q=20,
                             beta1=0.9, beta2=0.999, eps_adam=1e-8,
                             early_stop=True, verbose=False):
    """
    VR-ZO-AdaMM attack with SVRG variance reduction for ResNet model
    Algorithm from: VR‚ÄìZO‚ÄìAdaMM (Zeroth‚ÄìOrder Adam with SVRG Variance Reduction)
    """
    model_device = model
    image_shape = image_orig.shape
    d = image_orig.numel()

    if mu is None:
        mu = 1.0 / sqrt(max(1, T * d))

    proj = proj_l2_ball if norm == 'l2' else proj_linf_ball

    def f_query(x_arr):
        """Query function for model evaluation"""
        x_image = torch.FloatTensor(x_arr.reshape(image_shape)).to(device)
        probs = model_probabilities(model_device, x_image)
        return probs[true_label]

    # Initialize variables
    x_orig_np = image_orig.cpu().numpy().reshape(-1)
    x_current = x_orig_np.copy()

    queries = 0
    start = time.time()

    # Initial prediction
    init_pred, init_conf, _ = model_predict(model_device, image_orig.to(device))
    queries += 1

    if verbose:
        true_class_name = class_names[true_label]
        init_class_name = class_names[init_pred]
        print(f"[VR-ZO-AdaMM] True: {true_label}({true_class_name}), Initial: {init_pred}({init_class_name}), conf={init_conf:.6f}")

    # Number of outer loops (S)
    S = max(1, T // m)

    for s in range(S):
        # Line 3: xs,0 = xs
        x_s0 = x_current.copy()

        # Line 4-6: Compute reference gradient with large batch Q
        g_tilde = np.zeros(d, dtype=float)
        for i in range(Q):
            u = np.random.normal(size=d)
            u = u / (np.linalg.norm(u) + 1e-12)

            f_plus = f_query(x_s0 + mu * u)
            f_minus = f_query(x_s0 - mu * u)

            g_tilde += ((f_plus - f_minus) / (2 * mu)) * u
            queries += 2

        g_tilde = (d / Q) * g_tilde

        # Line 7: Initialize moments for inner loop
        m_inner = np.zeros(d, dtype=float)
        v_inner = np.zeros(d, dtype=float)
        v_hat_inner = np.zeros(d, dtype=float)

        # Inner loop (t = 0 to m-1)
        for t in range(m):
            # Line 9-10: Sample q random directions
            g_hat_current = np.zeros(d, dtype=float)
            g_hat_ref = np.zeros(d, dtype=float)

            for i in range(q):
                u = np.random.normal(size=d)
                u = u / (np.linalg.norm(u) + 1e-12)

                # Current point gradient
                f_plus_current = f_query(x_current + mu * u)
                f_minus_current = f_query(x_current - mu * u)
                g_hat_current += ((f_plus_current - f_minus_current) / (2 * mu)) * u

                # Reference point gradient
                f_plus_ref = f_query(x_s0 + mu * u)
                f_minus_ref = f_query(x_s0 - mu * u)
                g_hat_ref += ((f_plus_ref - f_minus_ref) / (2 * mu)) * u

                queries += 4

            g_hat_current = (d / q) * g_hat_current
            g_hat_ref = (d / q) * g_hat_ref

            # Line 13: Variance-reduced gradient
            g_vr = g_hat_current - g_hat_ref + g_tilde

            # Line 14-15: Adam moments
            m_inner = beta1 * m_inner + (1 - beta1) * g_vr
            v_inner = beta2 * v_inner + (1 - beta2) * (g_vr ** 2)

            # Bias correction
            m_hat = m_inner / (1 - beta1 ** (t + 1))
            v_hat = v_inner / (1 - beta2 ** (t + 1))

            # Line 16: AMSGrad correction
            v_hat_inner = np.maximum(v_hat_inner, v_hat)

            # Line 17: Adaptive update
            x_new = x_current - alpha * m_hat / (np.sqrt(v_hat_inner) + eps_adam)

            # Line 18: Projection
            perturbation = x_new - x_orig_np
            perturbation_projected = proj(perturbation, eps)
            x_current = x_orig_np + perturbation_projected

            # Clip to valid image range
            x_reshaped = x_current.reshape(image_shape)
            x_reshaped = np.clip(x_reshaped, -2.0, 2.0)
            x_current = x_reshaped.reshape(-1)

            # Check attack success
            x_image = torch.FloatTensor(x_current.reshape(image_shape)).to(device)
            pred_label, conf, _ = model_predict(model_device, x_image)
            queries += 1

            success = (pred_label != true_label)

            if verbose and ((s * m + t) % 50 == 0 or success):
                current_perturb_norm = np.linalg.norm(x_current - x_orig_np)
                pred_class_name = class_names[pred_label]
                print(f"Outer {s}, Inner {t}: pred={pred_label}({pred_class_name}), "
                      f"conf={conf:.4f}, perturb_norm={current_perturb_norm:.4f}, success={success}")

            if success and early_stop:
                end = time.time()
                delta = x_current - x_orig_np
                return {
                    "method": "VR-ZO-AdaMM",
                    "success": True,
                    "final_label": pred_label,
                    "final_confidence": conf,
                    "delta": delta.copy(),
                    "norm": np.linalg.norm(delta),
                    "queries": queries,
                    "iters": s * m + t + 1,
                    "time_sec": end - start
                }

    end = time.time()
    x_image = torch.FloatTensor(x_current.reshape(image_shape)).to(device)
    pred_label, conf, _ = model_predict(model_device, x_image)
    delta = x_current - x_orig_np

    return {
        "method": "VR-ZO-AdaMM",
        "success": (pred_label != true_label),
        "final_label": pred_label,
        "final_confidence": conf,
        "delta": delta.copy(),
        "norm": np.linalg.norm(delta),
        "queries": queries,
        "iters": S * m,
        "time_sec": end - start
    }

# =====================================================================================
# 21. COMPREHENSIVE COMPARISON WITH 5 RANDOM SAMPLES
# =====================================================================================

def comprehensive_comparison_5_samples(model, test_loader, num_samples=5):
    """
    Run comprehensive comparison on 5 random samples with all three methods
    """
    # Get correctly classified samples
    correctly_classified = []
    for idx, (image, true_label) in enumerate(test_loader):
        if idx >= 100:
            break
        with torch.no_grad():
            image = image.to(device)
            output = model(image)
            pred_class = torch.argmax(output, dim=1).item()
            if pred_class == true_label.item():
                correctly_classified.append(idx)

    # Select 5 random samples
    import random
    random.seed(42)  # For reproducibility
    selected_indices = random.sample(correctly_classified, min(num_samples, len(correctly_classified)))

    print(f"\nüéØ Selected {len(selected_indices)} random samples for comprehensive comparison:")
    for idx in selected_indices:
        image, true_label = test_loader.dataset[idx]
        pred, conf, _ = model_predict(model, image.unsqueeze(0).to(device))
        print(f"  Index {idx}: True={true_label}({class_names[true_label]}), "
              f"Pred={pred}({class_names[pred]}), Confidence={conf:.4f}")

    # Attack parameters
    attack_params = {
        'eps': 8.0,
        'norm': 'l2',
        'T': 200,
        'q': 10,
        'early_stop': True,
        'verbose': False
    }

    vr_params = {
        'eps': 8.0,
        'norm': 'l2',
        'T': 200,
        'q': 5,
        'm': 20,
        'Q': 10,
        'alpha': 0.05,
        'early_stop': True,
        'verbose': False
    }

    results = []

    for i, idx in enumerate(selected_indices):
        print(f"\nüî¨ Processing sample {i+1}/{len(selected_indices)} (Index {idx})")

        # Get the test sample
        image_orig, true_label = test_loader.dataset[idx]
        image_orig = image_orig.unsqueeze(0)

        # Get original prediction
        orig_pred, orig_conf, orig_probs = model_predict(model, image_orig.to(device))

        # Run all three attacks
        print("  Running ZO-AdaMM...")
        res_adamm = zo_adamm_attack_resnet(model, image_orig, true_label,
                                         **{**attack_params, 'alpha': 0.05})

        print("  Running ZO-SGD...")
        res_sgd = zo_sgd_attack_resnet(model, image_orig, true_label,
                                     **{**attack_params, 'lr': 0.05})

        print("  Running VR-ZO-AdaMM...")
        res_vr_adamm = vr_zo_adamm_attack_resnet(model, image_orig, true_label, **vr_params)

        # Calculate metrics
        results.append({
            "sample_index": idx,
            "true_label": true_label,
            "true_class": class_names[true_label],
            "original_confidence": orig_conf,

            # ZO-AdaMM results
            "adamm_success": res_adamm["success"],
            "adamm_queries": res_adamm["queries"],
            "adamm_norm": res_adamm["norm"],
            "adamm_final_confidence": res_adamm["final_confidence"],
            "adamm_confidence_drop": orig_conf - res_adamm["final_confidence"],
            "adamm_time": res_adamm["time_sec"],

            # ZO-SGD results
            "sgd_success": res_sgd["success"],
            "sgd_queries": res_sgd["queries"],
            "sgd_norm": res_sgd["norm"],
            "sgd_final_confidence": res_sgd["final_confidence"],
            "sgd_confidence_drop": orig_conf - res_sgd["final_confidence"],
            "sgd_time": res_sgd["time_sec"],

            # VR-ZO-AdaMM results
            "vr_adamm_success": res_vr_adamm["success"],
            "vr_adamm_queries": res_vr_adamm["queries"],
            "vr_adamm_norm": res_vr_adamm["norm"],
            "vr_adamm_final_confidence": res_vr_adamm["final_confidence"],
            "vr_adamm_confidence_drop": orig_conf - res_vr_adamm["final_confidence"],
            "vr_adamm_time": res_vr_adamm["time_sec"],
        })

        print(f"  ‚úì Completed: AdaMM({res_adamm['success']}), SGD({res_sgd['success']}), VR-AdaMM({res_vr_adamm['success']})")

    return results, selected_indices

# =====================================================================================
# 22. CREATE COMPREHENSIVE COMPARISON TABLE
# =====================================================================================

def create_comparison_table(results):
    """
    Create a comprehensive comparison table for the results
    """
    print("\n" + "="*100)
    print("üìä COMPREHENSIVE COMPARISON TABLE - 5 RANDOM SAMPLES")
    print("="*100)

    # Header
    header = f"{'Sample':<8} {'True Class':<15} {'Method':<12} {'Success':<8} {'Queries':<8} {'Perturb Norm':<12} {'Final Conf':<10} {'Conf Drop':<10} {'Time(s)':<8}"
    print(header)
    print("-" * 100)

    for i, result in enumerate(results):
        sample_info = f"Sample {i+1}"
        true_class = result['true_class']

        # ZO-AdaMM row
        adamm_success = "‚úì" if result['adamm_success'] else "‚úó"
        print(f"{sample_info:<8} {true_class:<15} {'ZO-AdaMM':<12} {adamm_success:<8} "
              f"{result['adamm_queries']:<8} {result['adamm_norm']:<12.4f} "
              f"{result['adamm_final_confidence']:<10.4f} {result['adamm_confidence_drop']:<10.4f} "
              f"{result['adamm_time']:<8.2f}")

        # ZO-SGD row
        sgd_success = "‚úì" if result['sgd_success'] else "‚úó"
        print(f"{'':<8} {'':<15} {'ZO-SGD':<12} {sgd_success:<8} "
              f"{result['sgd_queries']:<8} {result['sgd_norm']:<12.4f} "
              f"{result['sgd_final_confidence']:<10.4f} {result['sgd_confidence_drop']:<10.4f} "
              f"{result['sgd_time']:<8.2f}")

        # VR-ZO-AdaMM row
        vr_success = "‚úì" if result['vr_adamm_success'] else "‚úó"
        print(f"{'':<8} {'':<15} {'VR-ZO-AdaMM':<12} {vr_success:<8} "
              f"{result['vr_adamm_queries']:<8} {result['vr_adamm_norm']:<12.4f} "
              f"{result['vr_adamm_final_confidence']:<10.4f} {result['vr_adamm_confidence_drop']:<10.4f} "
              f"{result['vr_adamm_time']:<8.2f}")

        print("-" * 100)

# =====================================================================================
# 23. PERFORMANCE SUMMARY STATISTICS
# =====================================================================================

def calculate_performance_summary(results):
    """
    Calculate performance summary statistics
    """
    print("\n" + "="*80)
    print("üìà PERFORMANCE SUMMARY STATISTICS")
    print("="*80)

    # Convert to DataFrame for easier analysis
    import pandas as pd
    df = pd.DataFrame(results)

    methods = ['adamm', 'sgd', 'vr_adamm']
    method_names = ['ZO-AdaMM', 'ZO-SGD', 'VR-ZO-AdaMM']

    summary_data = []

    for method, name in zip(methods, method_names):
        success_rate = df[f'{method}_success'].mean()
        avg_queries = df[f'{method}_queries'].mean()
        avg_norm = df[f'{method}_norm'].mean()
        avg_confidence_drop = df[df[f'{method}_success']][f'{method}_confidence_drop'].mean() if df[f'{method}_success'].sum() > 0 else 0
        avg_time = df[f'{method}_time'].mean()
        success_count = df[f'{method}_success'].sum()

        summary_data.append({
            'Method': name,
            'Success Rate': f"{success_rate:.1%}",
            'Avg Queries': f"{avg_queries:.0f}",
            'Avg Perturb Norm': f"{avg_norm:.4f}",
            'Avg Conf Drop (Success)': f"{avg_confidence_drop:.4f}",
            'Avg Time (s)': f"{avg_time:.2f}",
            'Successful Attacks': f"{success_count}/{len(df)}"
        })

    summary_df = pd.DataFrame(summary_data)

    # Print summary table
    print(f"{'Method':<15} {'Success Rate':<12} {'Avg Queries':<12} {'Avg Norm':<12} {'Avg Conf Drop':<15} {'Avg Time(s)':<12} {'Success Count':<15}")
    print("-" * 80)
    for _, row in summary_df.iterrows():
        print(f"{row['Method']:<15} {row['Success Rate']:<12} {row['Avg Queries']:<12} {row['Avg Perturb Norm']:<12} "
              f"{row['Avg Conf Drop (Success)']:<15} {row['Avg Time (s)']:<12} {row['Successful Attacks']:<15}")

    return summary_df

# =====================================================================================
# 24. QUERY EFFICIENCY ANALYSIS
# =====================================================================================

def query_efficiency_analysis(results):
    """
    Analyze query efficiency across methods
    """
    print("\n" + "="*60)
    print("üîç QUERY EFFICIENCY ANALYSIS")
    print("="*60)

    df = pd.DataFrame(results)

    # Query efficiency for successful attacks only
    successful_attacks = df[(df['adamm_success']) | (df['sgd_success']) | (df['vr_adamm_success'])]

    if len(successful_attacks) > 0:
        print("Query counts for successful attacks:")
        for method, name in zip(['adamm', 'sgd', 'vr_adamm'], ['ZO-AdaMM', 'ZO-SGD', 'VR-ZO-AdaMM']):
            method_success = successful_attacks[successful_attacks[f'{method}_success']]
            if len(method_success) > 0:
                min_q = method_success[f'{method}_queries'].min()
                max_q = method_success[f'{method}_queries'].max()
                avg_q = method_success[f'{method}_queries'].mean()
                print(f"  {name}: Min={min_q}, Max={max_q}, Avg={avg_q:.0f}")

        # Query reduction percentage
        if len(successful_attacks[successful_attacks['adamm_success']]) > 0 and len(successful_attacks[successful_attacks['sgd_success']]) > 0:
            adamm_avg = successful_attacks[successful_attacks['adamm_success']]['adamm_queries'].mean()
            sgd_avg = successful_attacks[successful_attacks['sgd_success']]['sgd_queries'].mean()
            reduction_vs_sgd = ((sgd_avg - adamm_avg) / sgd_avg) * 100
            print(f"\nZO-AdaMM query reduction vs ZO-SGD: {reduction_vs_sgd:.1f}%")

        if len(successful_attacks[successful_attacks['vr_adamm_success']]) > 0 and len(successful_attacks[successful_attacks['adamm_success']]) > 0:
            vr_avg = successful_attacks[successful_attacks['vr_adamm_success']]['vr_adamm_queries'].mean()
            adamm_avg = successful_attacks[successful_attacks['adamm_success']]['adamm_queries'].mean()
            reduction_vs_adamm = ((adamm_avg - vr_avg) / adamm_avg) * 100
            print(f"VR-ZO-AdaMM query reduction vs ZO-AdaMM: {reduction_vs_adamm:.1f}%")

# =====================================================================================
# 25. RUN COMPREHENSIVE COMPARISON
# =====================================================================================

print("\n" + "="*80)
print("üöÄ STARTING COMPREHENSIVE COMPARISON - 5 RANDOM SAMPLES")
print("="*80)

# Run the comprehensive comparison
results, selected_indices = comprehensive_comparison_5_samples(model, test_loader_single, num_samples=5)

# Create comparison table
create_comparison_table(results)

# Calculate performance summary
summary_df = calculate_performance_summary(results)

# Query efficiency analysis
query_efficiency_analysis(results)

# =====================================================================================
# 26. VISUALIZATION OF RESULTS
# =====================================================================================

print("\n" + "="*80)
print("üìä GENERATING COMPARISON VISUALIZATIONS")
print("="*80)

# Create visualizations
fig, axes = plt.subplots(2, 3, figsize=(18, 12))

# Plot 1: Success Rate Comparison
success_rates = [
    sum(r['adamm_success'] for r in results) / len(results),
    sum(r['sgd_success'] for r in results) / len(results),
    sum(r['vr_adamm_success'] for r in results) / len(results)
]
methods = ['ZO-AdaMM', 'ZO-SGD', 'VR-ZO-AdaMM']
axes[0, 0].bar(methods, success_rates, color=['skyblue', 'lightcoral', 'lightgreen'])
axes[0, 0].set_title('Success Rate Comparison')
axes[0, 0].set_ylabel('Success Rate')
axes[0, 0].set_ylim(0, 1)
for i, v in enumerate(success_rates):
    axes[0, 0].text(i, v + 0.02, f'{v:.1%}', ha='center')

# Plot 2: Average Query Count
avg_queries = [
    sum(r['adamm_queries'] for r in results) / len(results),
    sum(r['sgd_queries'] for r in results) / len(results),
    sum(r['vr_adamm_queries'] for r in results) / len(results)
]
axes[0, 1].bar(methods, avg_queries, color=['skyblue', 'lightcoral', 'lightgreen'])
axes[0, 1].set_title('Average Query Count')
axes[0, 1].set_ylabel('Queries')
for i, v in enumerate(avg_queries):
    axes[0, 1].text(i, v + 5, f'{v:.0f}', ha='center')

# Plot 3: Average Perturbation Norm
avg_norms = [
    sum(r['adamm_norm'] for r in results) / len(results),
    sum(r['sgd_norm'] for r in results) / len(results),
    sum(r['vr_adamm_norm'] for r in results) / len(results)
]
axes[0, 2].bar(methods, avg_norms, color=['skyblue', 'lightcoral', 'lightgreen'])
axes[0, 2].set_title('Average Perturbation Norm')
axes[0, 2].set_ylabel('L2 Norm')
for i, v in enumerate(avg_norms):
    axes[0, 2].text(i, v + 0.1, f'{v:.3f}', ha='center')

# Plot 4: Query Distribution (Box plot)
query_data = []
for r in results:
    if r['adamm_success']:
        query_data.append(['ZO-AdaMM', r['adamm_queries']])
    if r['sgd_success']:
        query_data.append(['ZO-SGD', r['sgd_queries']])
    if r['vr_adamm_success']:
        query_data.append(['VR-ZO-AdaMM', r['vr_adamm_queries']])
query_df = pd.DataFrame(query_data, columns=['Method', 'Queries'])
if len(query_df) > 0:
    sns.boxplot(data=query_df, x='Method', y='Queries', ax=axes[1, 0])
    axes[1, 0].set_title('Query Distribution (Successful Attacks)')
else:
    axes[1, 0].text(0.5, 0.5, 'No successful attacks', ha='center', va='center')
    axes[1, 0].set_title('Query Distribution')

# Plot 5: Confidence Reduction
conf_drop_data = []
for r in results:
    if r['adamm_success']:
        conf_drop_data.append(['ZO-AdaMM', r['adamm_confidence_drop']])
    if r['sgd_success']:
        conf_drop_data.append(['ZO-SGD', r['sgd_confidence_drop']])
    if r['vr_adamm_success']:
        conf_drop_data.append(['VR-ZO-AdaMM', r['vr_adamm_confidence_drop']])
conf_drop_df = pd.DataFrame(conf_drop_data, columns=['Method', 'Confidence_Drop'])
if len(conf_drop_df) > 0:
    sns.boxplot(data=conf_drop_df, x='Method', y='Confidence_Drop', ax=axes[1, 1])
    axes[1, 1].set_title('Confidence Reduction (Successful Attacks)')
else:
    axes[1, 1].text(0.5, 0.5, 'No successful attacks', ha='center', va='center')
    axes[1, 1].set_title('Confidence Reduction')

# Plot 6: Computation Time
time_data = []
for r in results:
    time_data.append(['ZO-AdaMM', r['adamm_time']])
    time_data.append(['ZO-SGD', r['sgd_time']])
    time_data.append(['VR-ZO-AdaMM', r['vr_adamm_time']])
time_df = pd.DataFrame(time_data, columns=['Method', 'Time'])
sns.boxplot(data=time_df, x='Method', y='Time', ax=axes[1, 2])
axes[1, 2].set_title('Computation Time Distribution')

plt.tight_layout()
plt.savefig('comprehensive_comparison_5_samples.png', dpi=300, bbox_inches='tight')
plt.show()

print(f"üìä Visualizations saved as 'comprehensive_comparison_5_samples.png'")

# =====================================================================================
# 27. FINAL CONCLUSIONS
# =====================================================================================

print("\n" + "="*80)
print("üéØ FINAL CONCLUSIONS - VR-ZO-AdaMM vs ZO-AdaMM vs ZO-SGD")
print("="*80)

# Determine the best method
success_counts = {
    'ZO-AdaMM': sum(r['adamm_success'] for r in results),
    'ZO-SGD': sum(r['sgd_success'] for r in results),
    'VR-ZO-AdaMM': sum(r['vr_adamm_success'] for r in results)
}

avg_queries_dict = {
    'ZO-AdaMM': sum(r['adamm_queries'] for r in results) / len(results),
    'ZO-SGD': sum(r['sgd_queries'] for r in results) / len(results),
    'VR-ZO-AdaMM': sum(r['vr_adamm_queries'] for r in results) / len(results)
}

best_success = max(success_counts, key=success_counts.get)
best_efficiency = min(avg_queries_dict, key=avg_queries_dict.get)

print(f"üèÜ Best Success Rate: {best_success} ({success_counts[best_success]}/{len(results)} samples)")
print(f"üèÜ Most Query-Efficient: {best_efficiency} ({avg_queries_dict[best_efficiency]:.0f} avg queries)")

if best_success == best_efficiency:
    print(f"üéØ {best_success} demonstrates both highest success rate and best query efficiency!")
else:
    print(f"üîç Trade-off: {best_success} has best success, {best_efficiency} has best efficiency")

print(f"\nüí° Key Insights:")
print(f"   ‚Ä¢ VR-ZO-AdaMM uses SVRG variance reduction for potentially faster convergence")
print(f"   ‚Ä¢ ZO-AdaMM provides adaptive learning rates for stable optimization")
print(f"   ‚Ä¢ ZO-SGD serves as a simple baseline for comparison")

print(f"\nüìÅ Results Summary:")
print(f"   ‚Ä¢ Comparison table showing detailed results for 5 random samples")
print(f"   ‚Ä¢ Performance statistics for all three methods")
print(f"   ‚Ä¢ Query efficiency analysis")
print(f"   ‚Ä¢ Comprehensive visualizations")

print(f"\n‚úÖ Comprehensive comparison completed successfully!")